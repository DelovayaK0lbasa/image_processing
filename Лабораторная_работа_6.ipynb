{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0Da30HgH1-y"
   },
   "source": [
    "# Лабораторная работа 6. Обработка видео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XonJIlynID9d"
   },
   "source": [
    "## Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpZXX3wPIF4u"
   },
   "source": [
    "Локально на своем компьютере выполните детекцию движения, движущиеся объекты на видео либо потока с камеры должны выделяться контуром. Добейтесь, чтобы неподвижные предметы контуром не выделялись.\n",
    "\n",
    "1. Получите поток видео\n",
    "2. Используйте cv2.absdiff(frame1, frame2), чтобы выявить разницу между кадрами.\n",
    "3. Переведите результат в полутоновой вид\n",
    "4. Проведите пороговую бинаризацию\n",
    "5. Найдите контуры\n",
    "6. Наложите контуры поверх frame1\n",
    "7. Выведите frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация захвата видео (из камеры или файла)\n",
    "cap = cv2.VideoCapture('car_flow.mp4') \n",
    "ret, frame1 = cap.read()\n",
    "frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame2_gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    diff = cv2.absdiff(frame1_gray, frame2_gray)\n",
    "\n",
    "    # пороговая бинаризация\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Находим контуры\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 120:\n",
    "            cv2.drawContours(frame1, [contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Motion Detection', frame1)\n",
    "\n",
    "    frame1_gray = frame2_gray.copy()\n",
    "    frame1 = frame2.copy()\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc0EuYYQItai"
   },
   "source": [
    "## Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u85RskuPIvsY"
   },
   "source": [
    "Реализуйте на примере какого-нибудь видео трекинг на основе Deep-Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils.displayIO import display # в локальной версии для вывода\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Replace 'your_video_path.mp4' with the actual video file path\n",
    "input_video_path = 'car_flow.mp4'\n",
    "output_video_path = 'deepsort_output_video.avi'\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add object detection algorithm\n",
    "detector = wf.add_task(name=\"infer_yolo_v7\", auto_connect=True)\n",
    "\n",
    "# Add deepsort tracking algorithm\n",
    "tracking = wf.add_task(name=\"infer_deepsort\", auto_connect=True)\n",
    "\n",
    "tracking.set_parameters({\n",
    "    \"categories\": \"all\",\n",
    "    \"conf_thres\": \"0.5\",\n",
    "})\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties for the output\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "# The 'XVID' codec is widely supported and provides good quality\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    end, frame = cap.read()\n",
    "\n",
    "    # Test if the video has ended or there is an error\n",
    "    if not end:\n",
    "        print(\"Info: End of video or error.\")\n",
    "        break\n",
    "\n",
    "    # Run the workflow on current frame\n",
    "    wf.run_on(array=frame)\n",
    "\n",
    "    # Get results\n",
    "    image_out = tracking.get_output(0)\n",
    "    obj_detect_out = tracking.get_output(1)\n",
    "\n",
    "    # Convert the result to BGR color space for displaying\n",
    "    img_out = image_out.get_image_with_graphics(obj_detect_out)\n",
    "    img_res = cv2.cvtColor(img_out, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Save the resulting frame\n",
    "    out.write(img_out)\n",
    "\n",
    "    #  Display\n",
    "    cv2.imshow('video', img_res)\n",
    "\n",
    "    # Press 'q' to quit the video processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release everything\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11chFxqsVani"
   },
   "source": [
    "## Задача 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iq7kpCpVanm"
   },
   "source": [
    "Реализуйте на примере какого-нибудь видео из встроенных в VideoAssets трекинг на основе ByteTrack с подсчетом объектов, пересекающих заданную вами линию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "!pip install ultralytics==8.3.19\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "!pip install supervision[assets]==0.24.0\n",
    "import supervision as sv\n",
    "print(\"supervision.__version__:\", sv.__version__)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8x.pt\")\n",
    "\n",
    "SOURCE_VIDEO_PATH = \"car_flow.mp4\"\n",
    "\n",
    "# получаем словарь соответствия class_id и class_name\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "\n",
    "# выбираем классы\n",
    "SELECTED_CLASS_NAMES = ['car', 'motorcycle', 'bus', 'truck']\n",
    "\n",
    "# id выбранных классов\n",
    "SELECTED_CLASS_IDS = [\n",
    "    {value: key for key, value in CLASS_NAMES_DICT.items()}[class_name]\n",
    "    for class_name\n",
    "    in SELECTED_CLASS_NAMES\n",
    "]\n",
    "\n",
    "# генератор фреймов\n",
    "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "# определяем BoxAnnotator and LabelAnnotator\n",
    "box_annotator = sv.BoxAnnotator(thickness=1)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5, text_color=sv.Color.BLACK, text_padding=2)\n",
    "\n",
    "# получаем первый видеокадр\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# прогнозирование модели по одному кадру\n",
    "results = model(frame, verbose=False)[0]\n",
    "\n",
    "# преобразование в Detections\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "# учитываем только идентификатор класса из выбранных_классов, определенных выше\n",
    "detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]\n",
    "\n",
    "# форматирование custom labels, т.е. определяем как будут выглядеть custom labels\n",
    "labels = [\n",
    "    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "    for confidence, class_id in zip(detections.confidence, detections.class_id)\n",
    "]\n",
    "\n",
    "# аннотирование и отображение рамки\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = box_annotator.annotate(\n",
    "    scene=annotated_frame, detections=detections)\n",
    "annotated_frame = label_annotator.annotate(\n",
    "    scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline\n",
    "sv.plot_image(annotated_frame, (15, 10))\n",
    "\n",
    "# настройки линии\n",
    "LINE_START = sv.Point(0 + 50, 1500)\n",
    "LINE_END = sv.Point(3840 - 50, 1500)\n",
    "\n",
    "TARGET_VIDEO_PATH = f\"{HOME}/result.mp4\"\n",
    "\n",
    "sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "\n",
    "# создать экземпляр BYTETracker\n",
    "byte_tracker = sv.ByteTrack(\n",
    "    track_activation_threshold=0.25, # Порог достоверности обнаружения для активации трека\n",
    "    lost_track_buffer=30, # Количество кадров для буферизации при потере трека\n",
    "    minimum_matching_threshold=0.8, # Порог для сопоставления треков с обнаружениями.\n",
    "    frame_rate=30,\n",
    "    minimum_consecutive_frames=3) # Количество последовательных кадров, в течение которых объект должен отслеживаться, прежде чем он будет считаться «действительным» треком.\n",
    "\n",
    "byte_tracker.reset()\n",
    "\n",
    "# создать экземпляр VideoInfo\n",
    "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "\n",
    "# создать frame generator\n",
    "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "\n",
    "# создайте экземпляр LineZone, ранее он назывался классом LineCounter\n",
    "line_zone = sv.LineZone(start=LINE_START, end=LINE_END)\n",
    "\n",
    "# создание BoxAnnotator, LabelAnnotator, и TraceAnnotator\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(text_thickness=1, text_scale=0.5, text_color=sv.Color.BLACK, text_padding=2)\n",
    "trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=50)\n",
    "\n",
    "# создание экземпляра LineZoneAnnotator, ранее он назывался классом LineCounterAnnotator\n",
    "line_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "\n",
    "# define call back function to be used in video processing\n",
    "def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
    "    # model prediction on single frame and conversion to supervision Detections\n",
    "    results = model(frame, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    # only consider class id from selected_classes define above\n",
    "    detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]\n",
    "    # tracking detections\n",
    "    detections = byte_tracker.update_with_detections(detections)\n",
    "    labels = [\n",
    "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
    "        for confidence, class_id, tracker_id\n",
    "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
    "    ]\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = trace_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = box_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(\n",
    "        scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "    # update line counter\n",
    "    line_zone.trigger(detections)\n",
    "    # return frame with box and line annotated result\n",
    "    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n",
    "\n",
    "# process the whole video\n",
    "sv.process_video(\n",
    "    source_path = SOURCE_VIDEO_PATH,\n",
    "    target_path = TARGET_VIDEO_PATH,\n",
    "    callback=callback\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
